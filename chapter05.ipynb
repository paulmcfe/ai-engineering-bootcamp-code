{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27281806",
   "metadata": {},
   "source": [
    "# Multi-Agent Applications with LangGraph\n",
    "\n",
    "## The Supervisor Pattern\n",
    "\n",
    "This notebook implements a multi-agent system using the **supervisor pattern** - a central coordinator that delegates tasks to specialized worker agents. Our team consists of:\n",
    "\n",
    "- **Supervisor**: Analyzes requests and coordinates the team\n",
    "- **Researcher**: Gathers information using web search\n",
    "- **Writer**: Creates content from research findings\n",
    "- **Editor**: Reviews and polishes the final content\n",
    "\n",
    "```\n",
    "                    ┌─────────────┐\n",
    "                    │  Supervisor │\n",
    "                    │    Agent    │\n",
    "                    └──────┬──────┘\n",
    "                           │\n",
    "           ┌───────────────┼───────────────┐\n",
    "           │               │               │\n",
    "           ▼               ▼               ▼\n",
    "    ┌────────────┐  ┌────────────┐  ┌────────────┐\n",
    "    │ Researcher │  │   Writer   │  │   Editor   │\n",
    "    │(web search)│  │   Agent    │  │   Agent    │\n",
    "    └────────────┘  └────────────┘  └────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oqgwks2jjx7",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375yb5ryp",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END, add_messages\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Initialize web search tool\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q43w2vdi7tp",
   "metadata": {},
   "source": [
    "## Define Shared State\n",
    "\n",
    "The `TeamState` manages information flow between agents. Each agent reads from and writes to specific fields, enabling coordination without direct communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ywy4hy27fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeamState(TypedDict):\n",
    "    \"\"\"Shared state for multi-agent coordination.\"\"\"\n",
    "    messages: Annotated[list, add_messages]   # Conversation history\n",
    "    user_request: str                         # Original user request\n",
    "    research_findings: str                    # Output from researcher\n",
    "    draft_content: str                        # Output from writer\n",
    "    edited_content: str                       # Output from editor\n",
    "    next_action: str                          # Supervisor's routing decision\n",
    "    final_response: str                       # Final output to user\n",
    "\n",
    "print(\"TeamState defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wo1hwpvona8",
   "metadata": {},
   "source": [
    "## Agent Prompts\n",
    "\n",
    "Each agent has a specialized system prompt that defines its role, capabilities, and guidelines. Clear role definitions prevent overlap and confusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ogu4oalb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPERVISOR_PROMPT = \"\"\"You coordinate a team of specialists to handle content creation requests.\n",
    "\n",
    "Your team:\n",
    "- RESEARCHER: Use for finding information, verifying facts, gathering data from the web\n",
    "- WRITER: Use for creating content, drafting documents, structuring information\n",
    "- EDITOR: Use for reviewing content, fixing errors, improving quality\n",
    "\n",
    "For each request, analyze what needs to be done and decide the next action.\n",
    "\n",
    "Current workflow state:\n",
    "- User request: {user_request}\n",
    "- Research findings: {research_findings}\n",
    "- Draft content: {draft_content}\n",
    "- Edited content: {edited_content}\n",
    "\n",
    "Based on the current state, decide the next action:\n",
    "- If no research has been done yet, delegate to RESEARCHER\n",
    "- If research is complete but no draft exists, delegate to WRITER\n",
    "- If a draft exists but hasn't been edited, delegate to EDITOR\n",
    "- If edited content exists, mark as COMPLETE\n",
    "\n",
    "Respond with JSON: {{\"next_action\": \"researcher\" | \"writer\" | \"editor\" | \"complete\", \"reasoning\": \"brief explanation\"}}\n",
    "\"\"\"\n",
    "\n",
    "RESEARCHER_PROMPT = \"\"\"You are a research specialist. Your job is to gather accurate, relevant information using web search.\n",
    "\n",
    "User request: {user_request}\n",
    "\n",
    "Instructions:\n",
    "1. Identify key topics that need research\n",
    "2. Search for factual, current information\n",
    "3. Synthesize findings into a clear summary\n",
    "4. Include relevant facts, statistics, and insights\n",
    "5. Note sources when possible\n",
    "\n",
    "Provide comprehensive research findings that will help a writer create quality content.\"\"\"\n",
    "\n",
    "WRITER_PROMPT = \"\"\"You are a content writer. Your job is to create well-structured, engaging content based on research.\n",
    "\n",
    "User request: {user_request}\n",
    "\n",
    "Research findings:\n",
    "{research_findings}\n",
    "\n",
    "Instructions:\n",
    "1. Create content that directly addresses the user's request\n",
    "2. Use the research findings to support your points\n",
    "3. Structure the content logically with clear sections\n",
    "4. Write in a clear, professional tone\n",
    "5. Make the content informative and engaging\n",
    "\n",
    "Create a complete draft based on the research provided.\"\"\"\n",
    "\n",
    "EDITOR_PROMPT = \"\"\"You are an editor. Your job is to review and improve written content.\n",
    "\n",
    "User request: {user_request}\n",
    "\n",
    "Draft to edit:\n",
    "{draft_content}\n",
    "\n",
    "Instructions:\n",
    "1. Review for clarity and readability\n",
    "2. Fix any grammatical or spelling errors\n",
    "3. Improve sentence structure and flow\n",
    "4. Ensure the content fully addresses the user's request\n",
    "5. Polish the writing to be professional and engaging\n",
    "\n",
    "Provide the final, polished version of the content.\"\"\"\n",
    "\n",
    "print(\"Agent prompts defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "n5v2xfmk6n",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Utility functions for JSON parsing and web search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gzhmx07pt9v",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_response(text: str, default: dict = None) -> dict:\n",
    "    \"\"\"Extract and parse JSON from LLM response, handling markdown code blocks.\"\"\"\n",
    "    if not text or not text.strip():\n",
    "        return default or {}\n",
    "    \n",
    "    # Try to find JSON in code blocks first\n",
    "    code_block_match = re.search(r'```(?:json)?\\s*([\\s\\S]*?)```', text)\n",
    "    if code_block_match:\n",
    "        text = code_block_match.group(1).strip()\n",
    "    \n",
    "    # Try to find JSON object or array\n",
    "    json_match = re.search(r'(\\{[\\s\\S]*\\}|\\[[\\s\\S]*\\])', text)\n",
    "    if json_match:\n",
    "        text = json_match.group(1)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        return default or {}\n",
    "\n",
    "\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Perform web search and return results.\"\"\"\n",
    "    try:\n",
    "        results = search_tool.run(query)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return f\"Search failed: {str(e)}\"\n",
    "\n",
    "print(\"Helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svjzzqc4p6",
   "metadata": {},
   "source": [
    "## Agent Node Functions\n",
    "\n",
    "Each agent is implemented as a node function that reads from state, performs its task, and returns state updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diap20mjuj4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_node(state: TeamState) -> dict:\n",
    "    \"\"\"Supervisor analyzes state and decides the next action.\"\"\"\n",
    "    \n",
    "    # Format the prompt with current state\n",
    "    prompt = SUPERVISOR_PROMPT.format(\n",
    "        user_request=state.get(\"user_request\", \"\"),\n",
    "        research_findings=state.get(\"research_findings\", \"None yet\"),\n",
    "        draft_content=state.get(\"draft_content\", \"None yet\"),\n",
    "        edited_content=state.get(\"edited_content\", \"None yet\")\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke([SystemMessage(content=prompt)])\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    default = {\"next_action\": \"researcher\", \"reasoning\": \"Starting with research\"}\n",
    "    result = parse_json_response(response.content, default)\n",
    "    \n",
    "    next_action = result.get(\"next_action\", \"researcher\")\n",
    "    reasoning = result.get(\"reasoning\", \"\")\n",
    "    \n",
    "    print(f\"[Supervisor] Decision: {next_action}\")\n",
    "    print(f\"[Supervisor] Reasoning: {reasoning}\\n\")\n",
    "    \n",
    "    return {\"next_action\": next_action}\n",
    "\n",
    "\n",
    "def researcher_node(state: TeamState) -> dict:\n",
    "    \"\"\"Researcher gathers information using web search.\"\"\"\n",
    "    \n",
    "    user_request = state.get(\"user_request\", \"\")\n",
    "    \n",
    "    print(\"[Researcher] Starting research...\")\n",
    "    \n",
    "    # Generate search queries based on the request\n",
    "    query_prompt = f\"\"\"Based on this content request, generate 2-3 search queries to gather relevant information.\n",
    "    \n",
    "Request: {user_request}\n",
    "\n",
    "Respond with JSON: {{\"queries\": [\"query1\", \"query2\"]}}\"\"\"\n",
    "    \n",
    "    query_response = llm.invoke([SystemMessage(content=query_prompt)])\n",
    "    queries_result = parse_json_response(query_response.content, {\"queries\": [user_request]})\n",
    "    queries = queries_result.get(\"queries\", [user_request])\n",
    "    \n",
    "    # Perform searches\n",
    "    all_results = []\n",
    "    for query in queries[:3]:  # Limit to 3 queries\n",
    "        print(f\"[Researcher] Searching: {query}\")\n",
    "        results = web_search(query)\n",
    "        all_results.append(f\"Search: {query}\\nResults: {results}\\n\")\n",
    "    \n",
    "    combined_results = \"\\n\".join(all_results)\n",
    "    \n",
    "    # Synthesize findings\n",
    "    synthesis_prompt = RESEARCHER_PROMPT.format(user_request=user_request)\n",
    "    synthesis_prompt += f\"\\n\\nSearch Results:\\n{combined_results}\\n\\nSynthesize these findings into a comprehensive summary.\"\n",
    "    \n",
    "    synthesis = llm.invoke([SystemMessage(content=synthesis_prompt)])\n",
    "    \n",
    "    print(\"[Researcher] Research complete!\\n\")\n",
    "    \n",
    "    return {\"research_findings\": synthesis.content}\n",
    "\n",
    "\n",
    "def writer_node(state: TeamState) -> dict:\n",
    "    \"\"\"Writer creates content based on research findings.\"\"\"\n",
    "    \n",
    "    print(\"[Writer] Creating draft...\")\n",
    "    \n",
    "    prompt = WRITER_PROMPT.format(\n",
    "        user_request=state.get(\"user_request\", \"\"),\n",
    "        research_findings=state.get(\"research_findings\", \"No research available\")\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke([SystemMessage(content=prompt)])\n",
    "    \n",
    "    print(\"[Writer] Draft complete!\\n\")\n",
    "    \n",
    "    return {\"draft_content\": response.content}\n",
    "\n",
    "\n",
    "def editor_node(state: TeamState) -> dict:\n",
    "    \"\"\"Editor reviews and polishes the content.\"\"\"\n",
    "    \n",
    "    print(\"[Editor] Editing content...\")\n",
    "    \n",
    "    prompt = EDITOR_PROMPT.format(\n",
    "        user_request=state.get(\"user_request\", \"\"),\n",
    "        draft_content=state.get(\"draft_content\", \"No draft available\")\n",
    "    )\n",
    "    \n",
    "    response = llm.invoke([SystemMessage(content=prompt)])\n",
    "    \n",
    "    print(\"[Editor] Editing complete!\\n\")\n",
    "    \n",
    "    return {\"edited_content\": response.content}\n",
    "\n",
    "\n",
    "def complete_node(state: TeamState) -> dict:\n",
    "    \"\"\"Finalize the response.\"\"\"\n",
    "    \n",
    "    print(\"[Complete] Finalizing response...\")\n",
    "    \n",
    "    final_content = state.get(\"edited_content\", state.get(\"draft_content\", \"\"))\n",
    "    \n",
    "    return {\"final_response\": final_content}\n",
    "\n",
    "print(\"Agent node functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ierqr3z3",
   "metadata": {},
   "source": [
    "## Routing Logic\n",
    "\n",
    "The router function directs the workflow based on the supervisor's decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w74ne3gep7g",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor_router(state: TeamState) -> Literal[\"researcher\", \"writer\", \"editor\", \"complete\"]:\n",
    "    \"\"\"Route to the appropriate agent based on supervisor's decision.\"\"\"\n",
    "    next_action = state.get(\"next_action\", \"researcher\")\n",
    "    \n",
    "    if next_action in [\"researcher\", \"writer\", \"editor\", \"complete\"]:\n",
    "        return next_action\n",
    "    \n",
    "    # Default to researcher if unknown action\n",
    "    return \"researcher\"\n",
    "\n",
    "print(\"Routing logic defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xg6p9bcibli",
   "metadata": {},
   "source": [
    "## Build the StateGraph\n",
    "\n",
    "Now we assemble all the pieces into a LangGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37x671rdzzq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the multi-agent graph\n",
    "graph = StateGraph(TeamState)\n",
    "\n",
    "# Add all agent nodes\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"researcher\", researcher_node)\n",
    "graph.add_node(\"writer\", writer_node)\n",
    "graph.add_node(\"editor\", editor_node)\n",
    "graph.add_node(\"complete\", complete_node)\n",
    "\n",
    "# Set the entry point\n",
    "graph.set_entry_point(\"supervisor\")\n",
    "\n",
    "# Add conditional edges from supervisor to workers\n",
    "graph.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    supervisor_router,\n",
    "    {\n",
    "        \"researcher\": \"researcher\",\n",
    "        \"writer\": \"writer\",\n",
    "        \"editor\": \"editor\",\n",
    "        \"complete\": \"complete\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Workers return to supervisor for next decision\n",
    "graph.add_edge(\"researcher\", \"supervisor\")\n",
    "graph.add_edge(\"writer\", \"supervisor\")\n",
    "graph.add_edge(\"editor\", \"supervisor\")\n",
    "\n",
    "# Complete leads to END\n",
    "graph.add_edge(\"complete\", END)\n",
    "\n",
    "# Compile the graph\n",
    "multi_agent_app = graph.compile()\n",
    "\n",
    "print(\"Multi-agent graph built and compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xbxziqopxz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph structure\n",
    "print(\"Graph Structure (ASCII):\")\n",
    "print(multi_agent_app.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j5kvmawihog",
   "metadata": {},
   "source": [
    "## Run the Multi-Agent System\n",
    "\n",
    "Let's test the system with a content creation request. The supervisor will coordinate the team through research, writing, and editing phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uc4vz9wr47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the multi-agent system\n",
    "test_request = \"Write a brief article about the benefits of multi-agent AI systems\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MULTI-AGENT CONTENT CREATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nUser Request: {test_request}\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run the multi-agent workflow\n",
    "result = multi_agent_app.invoke({\n",
    "    \"user_request\": test_request,\n",
    "    \"messages\": []\n",
    "})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL OUTPUT\")\n",
    "print(\"=\" * 60)\n",
    "print(result.get(\"final_response\", result.get(\"edited_content\", \"No output\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "g11jy4yg2pf",
   "metadata": {},
   "source": [
    "## Examining the Workflow State\n",
    "\n",
    "Let's look at what each agent produced during the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "l2k1f4ijsos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine what each agent produced\n",
    "print(\"=\" * 60)\n",
    "print(\"RESEARCH FINDINGS (from Researcher)\")\n",
    "print(\"=\" * 60)\n",
    "print(result.get(\"research_findings\", \"None\")[:1000] + \"...\" if len(result.get(\"research_findings\", \"\")) > 1000 else result.get(\"research_findings\", \"None\"))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DRAFT CONTENT (from Writer)\")\n",
    "print(\"=\" * 60)\n",
    "print(result.get(\"draft_content\", \"None\")[:1000] + \"...\" if len(result.get(\"draft_content\", \"\")) > 1000 else result.get(\"draft_content\", \"None\"))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EDITED CONTENT (from Editor)\")\n",
    "print(\"=\" * 60)\n",
    "print(result.get(\"edited_content\", \"None\")[:1000] + \"...\" if len(result.get(\"edited_content\", \"\")) > 1000 else result.get(\"edited_content\", \"None\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w7dvoui7fok",
   "metadata": {},
   "source": [
    "## Try Your Own Request\n",
    "\n",
    "Try running the multi-agent system with your own content request!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61r9atk619k",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own request\n",
    "your_request = \"Write a short summary about the latest trends in renewable energy\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CUSTOM REQUEST\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nUser Request: {your_request}\\n\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "custom_result = multi_agent_app.invoke({\n",
    "    \"user_request\": your_request,\n",
    "    \"messages\": []\n",
    "})\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL OUTPUT\")\n",
    "print(\"=\" * 60)\n",
    "print(custom_result.get(\"final_response\", custom_result.get(\"edited_content\", \"No output\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
